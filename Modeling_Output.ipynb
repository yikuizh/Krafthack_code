{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "1a9d26c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pylab as plt\n",
    "%matplotlib inline\n",
    "from matplotlib.pylab import rcParams\n",
    "import seaborn as sns\n",
    "\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a7ed5f42",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit_4_Power</th>\n",
       "      <th>Unit_4_Reactive Power</th>\n",
       "      <th>Turbine_Guide Vane Opening</th>\n",
       "      <th>Turbine_Pressure Drafttube</th>\n",
       "      <th>Turbine_Pressure Spiral Casing</th>\n",
       "      <th>Turbine_Rotational Speed</th>\n",
       "      <th>mode</th>\n",
       "      <th>Bolt_1_Steel tmp</th>\n",
       "      <th>Bolt_1_Tensile</th>\n",
       "      <th>Bolt_2_Tensile</th>\n",
       "      <th>...</th>\n",
       "      <th>Bolt_5_Tensile</th>\n",
       "      <th>Bolt_6_Tensile</th>\n",
       "      <th>Bolt_1_Torsion</th>\n",
       "      <th>Bolt_2_Torsion</th>\n",
       "      <th>Bolt_3_Torsion</th>\n",
       "      <th>Bolt_4_Torsion</th>\n",
       "      <th>Bolt_5_Torsion</th>\n",
       "      <th>Bolt_6_Torsion</th>\n",
       "      <th>lower_bearing_vib_vrt</th>\n",
       "      <th>turbine_bearing_vib_vrt</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timepoints</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1970-12-19 09:51:44</th>\n",
       "      <td>262.204308</td>\n",
       "      <td>2.899036</td>\n",
       "      <td>82.279976</td>\n",
       "      <td>173.955216</td>\n",
       "      <td>5310.799181</td>\n",
       "      <td>107.964278</td>\n",
       "      <td>operation</td>\n",
       "      <td>4.133996</td>\n",
       "      <td>1598.481390</td>\n",
       "      <td>1480.989917</td>\n",
       "      <td>...</td>\n",
       "      <td>1635.585700</td>\n",
       "      <td>1674.848803</td>\n",
       "      <td>175.758460</td>\n",
       "      <td>163.956613</td>\n",
       "      <td>146.288741</td>\n",
       "      <td>225.535170</td>\n",
       "      <td>297.780208</td>\n",
       "      <td>161.148100</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-12-19 09:51:45</th>\n",
       "      <td>262.104319</td>\n",
       "      <td>3.344630</td>\n",
       "      <td>82.277248</td>\n",
       "      <td>173.989815</td>\n",
       "      <td>5311.219755</td>\n",
       "      <td>107.964273</td>\n",
       "      <td>operation</td>\n",
       "      <td>4.134078</td>\n",
       "      <td>1598.477449</td>\n",
       "      <td>1480.989528</td>\n",
       "      <td>...</td>\n",
       "      <td>1635.588478</td>\n",
       "      <td>1674.823883</td>\n",
       "      <td>175.755164</td>\n",
       "      <td>163.951680</td>\n",
       "      <td>146.284164</td>\n",
       "      <td>225.527142</td>\n",
       "      <td>297.771627</td>\n",
       "      <td>161.145094</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-12-19 09:51:46</th>\n",
       "      <td>262.004330</td>\n",
       "      <td>3.790223</td>\n",
       "      <td>82.274520</td>\n",
       "      <td>174.024413</td>\n",
       "      <td>5311.640329</td>\n",
       "      <td>107.964269</td>\n",
       "      <td>operation</td>\n",
       "      <td>4.134731</td>\n",
       "      <td>1598.479316</td>\n",
       "      <td>1481.003188</td>\n",
       "      <td>...</td>\n",
       "      <td>1635.583464</td>\n",
       "      <td>1674.841318</td>\n",
       "      <td>175.764601</td>\n",
       "      <td>163.952007</td>\n",
       "      <td>146.283423</td>\n",
       "      <td>225.522291</td>\n",
       "      <td>297.777115</td>\n",
       "      <td>161.144487</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-12-19 09:51:47</th>\n",
       "      <td>261.904340</td>\n",
       "      <td>4.235817</td>\n",
       "      <td>82.271792</td>\n",
       "      <td>174.059012</td>\n",
       "      <td>5312.060902</td>\n",
       "      <td>107.964264</td>\n",
       "      <td>operation</td>\n",
       "      <td>4.134270</td>\n",
       "      <td>1598.490184</td>\n",
       "      <td>1481.028827</td>\n",
       "      <td>...</td>\n",
       "      <td>1635.581384</td>\n",
       "      <td>1674.843245</td>\n",
       "      <td>175.763157</td>\n",
       "      <td>163.953924</td>\n",
       "      <td>146.283633</td>\n",
       "      <td>225.535827</td>\n",
       "      <td>297.772578</td>\n",
       "      <td>161.144037</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1970-12-19 09:51:48</th>\n",
       "      <td>261.804351</td>\n",
       "      <td>4.064759</td>\n",
       "      <td>82.269064</td>\n",
       "      <td>174.153819</td>\n",
       "      <td>5312.405938</td>\n",
       "      <td>107.964259</td>\n",
       "      <td>operation</td>\n",
       "      <td>4.133583</td>\n",
       "      <td>1598.494073</td>\n",
       "      <td>1481.059017</td>\n",
       "      <td>...</td>\n",
       "      <td>1635.591746</td>\n",
       "      <td>1674.872300</td>\n",
       "      <td>175.760959</td>\n",
       "      <td>163.951968</td>\n",
       "      <td>146.286946</td>\n",
       "      <td>225.534231</td>\n",
       "      <td>297.774191</td>\n",
       "      <td>161.151967</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 22 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Unit_4_Power  Unit_4_Reactive Power  \\\n",
       "timepoints                                                 \n",
       "1970-12-19 09:51:44    262.204308               2.899036   \n",
       "1970-12-19 09:51:45    262.104319               3.344630   \n",
       "1970-12-19 09:51:46    262.004330               3.790223   \n",
       "1970-12-19 09:51:47    261.904340               4.235817   \n",
       "1970-12-19 09:51:48    261.804351               4.064759   \n",
       "\n",
       "                     Turbine_Guide Vane Opening  Turbine_Pressure Drafttube  \\\n",
       "timepoints                                                                    \n",
       "1970-12-19 09:51:44                   82.279976                  173.955216   \n",
       "1970-12-19 09:51:45                   82.277248                  173.989815   \n",
       "1970-12-19 09:51:46                   82.274520                  174.024413   \n",
       "1970-12-19 09:51:47                   82.271792                  174.059012   \n",
       "1970-12-19 09:51:48                   82.269064                  174.153819   \n",
       "\n",
       "                     Turbine_Pressure Spiral Casing  Turbine_Rotational Speed  \\\n",
       "timepoints                                                                      \n",
       "1970-12-19 09:51:44                     5310.799181                107.964278   \n",
       "1970-12-19 09:51:45                     5311.219755                107.964273   \n",
       "1970-12-19 09:51:46                     5311.640329                107.964269   \n",
       "1970-12-19 09:51:47                     5312.060902                107.964264   \n",
       "1970-12-19 09:51:48                     5312.405938                107.964259   \n",
       "\n",
       "                          mode  Bolt_1_Steel tmp  Bolt_1_Tensile  \\\n",
       "timepoints                                                         \n",
       "1970-12-19 09:51:44  operation          4.133996     1598.481390   \n",
       "1970-12-19 09:51:45  operation          4.134078     1598.477449   \n",
       "1970-12-19 09:51:46  operation          4.134731     1598.479316   \n",
       "1970-12-19 09:51:47  operation          4.134270     1598.490184   \n",
       "1970-12-19 09:51:48  operation          4.133583     1598.494073   \n",
       "\n",
       "                     Bolt_2_Tensile  ...  Bolt_5_Tensile  Bolt_6_Tensile  \\\n",
       "timepoints                           ...                                   \n",
       "1970-12-19 09:51:44     1480.989917  ...     1635.585700     1674.848803   \n",
       "1970-12-19 09:51:45     1480.989528  ...     1635.588478     1674.823883   \n",
       "1970-12-19 09:51:46     1481.003188  ...     1635.583464     1674.841318   \n",
       "1970-12-19 09:51:47     1481.028827  ...     1635.581384     1674.843245   \n",
       "1970-12-19 09:51:48     1481.059017  ...     1635.591746     1674.872300   \n",
       "\n",
       "                     Bolt_1_Torsion  Bolt_2_Torsion  Bolt_3_Torsion  \\\n",
       "timepoints                                                            \n",
       "1970-12-19 09:51:44      175.758460      163.956613      146.288741   \n",
       "1970-12-19 09:51:45      175.755164      163.951680      146.284164   \n",
       "1970-12-19 09:51:46      175.764601      163.952007      146.283423   \n",
       "1970-12-19 09:51:47      175.763157      163.953924      146.283633   \n",
       "1970-12-19 09:51:48      175.760959      163.951968      146.286946   \n",
       "\n",
       "                     Bolt_4_Torsion  Bolt_5_Torsion  Bolt_6_Torsion  \\\n",
       "timepoints                                                            \n",
       "1970-12-19 09:51:44      225.535170      297.780208      161.148100   \n",
       "1970-12-19 09:51:45      225.527142      297.771627      161.145094   \n",
       "1970-12-19 09:51:46      225.522291      297.777115      161.144487   \n",
       "1970-12-19 09:51:47      225.535827      297.772578      161.144037   \n",
       "1970-12-19 09:51:48      225.534231      297.774191      161.151967   \n",
       "\n",
       "                     lower_bearing_vib_vrt  turbine_bearing_vib_vrt  \n",
       "timepoints                                                           \n",
       "1970-12-19 09:51:44                    NaN                      NaN  \n",
       "1970-12-19 09:51:45                    NaN                      NaN  \n",
       "1970-12-19 09:51:46                    NaN                      NaN  \n",
       "1970-12-19 09:51:47                    NaN                      NaN  \n",
       "1970-12-19 09:51:48                    NaN                      NaN  \n",
       "\n",
       "[5 rows x 22 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the dataset\n",
    "PATH_TO_DATA = r'C:\\Users\\yzh086\\OneDrive - University of Bergen\\hackthon_code\\data\\input_dataset-2.parquet'\n",
    "data = pd.read_parquet(PATH_TO_DATA)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f68b3f74",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unit_4_Power</th>\n",
       "      <th>Unit_4_Reactive Power</th>\n",
       "      <th>Turbine_Guide Vane Opening</th>\n",
       "      <th>Turbine_Pressure Drafttube</th>\n",
       "      <th>Turbine_Pressure Spiral Casing</th>\n",
       "      <th>Turbine_Rotational Speed</th>\n",
       "      <th>mode</th>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>timepoints</th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "      <th></th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1971-01-25 11:06:49</th>\n",
       "      <td>308.867868</td>\n",
       "      <td>5.592261</td>\n",
       "      <td>94.442351</td>\n",
       "      <td>158.159044</td>\n",
       "      <td>5279.876581</td>\n",
       "      <td>108.057467</td>\n",
       "      <td>operation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-01-25 11:06:50</th>\n",
       "      <td>308.898237</td>\n",
       "      <td>6.251969</td>\n",
       "      <td>94.445687</td>\n",
       "      <td>158.202829</td>\n",
       "      <td>5279.930843</td>\n",
       "      <td>108.057460</td>\n",
       "      <td>operation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-01-25 11:06:51</th>\n",
       "      <td>308.928605</td>\n",
       "      <td>7.037091</td>\n",
       "      <td>94.449024</td>\n",
       "      <td>158.246614</td>\n",
       "      <td>5279.985105</td>\n",
       "      <td>108.057454</td>\n",
       "      <td>operation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-01-25 11:06:52</th>\n",
       "      <td>308.958974</td>\n",
       "      <td>7.822213</td>\n",
       "      <td>94.452361</td>\n",
       "      <td>158.290399</td>\n",
       "      <td>5280.039368</td>\n",
       "      <td>108.057448</td>\n",
       "      <td>operation</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1971-01-25 11:06:53</th>\n",
       "      <td>308.989343</td>\n",
       "      <td>8.607335</td>\n",
       "      <td>94.455698</td>\n",
       "      <td>158.302931</td>\n",
       "      <td>5280.058748</td>\n",
       "      <td>108.057442</td>\n",
       "      <td>operation</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     Unit_4_Power  Unit_4_Reactive Power  \\\n",
       "timepoints                                                 \n",
       "1971-01-25 11:06:49    308.867868               5.592261   \n",
       "1971-01-25 11:06:50    308.898237               6.251969   \n",
       "1971-01-25 11:06:51    308.928605               7.037091   \n",
       "1971-01-25 11:06:52    308.958974               7.822213   \n",
       "1971-01-25 11:06:53    308.989343               8.607335   \n",
       "\n",
       "                     Turbine_Guide Vane Opening  Turbine_Pressure Drafttube  \\\n",
       "timepoints                                                                    \n",
       "1971-01-25 11:06:49                   94.442351                  158.159044   \n",
       "1971-01-25 11:06:50                   94.445687                  158.202829   \n",
       "1971-01-25 11:06:51                   94.449024                  158.246614   \n",
       "1971-01-25 11:06:52                   94.452361                  158.290399   \n",
       "1971-01-25 11:06:53                   94.455698                  158.302931   \n",
       "\n",
       "                     Turbine_Pressure Spiral Casing  Turbine_Rotational Speed  \\\n",
       "timepoints                                                                      \n",
       "1971-01-25 11:06:49                     5279.876581                108.057467   \n",
       "1971-01-25 11:06:50                     5279.930843                108.057460   \n",
       "1971-01-25 11:06:51                     5279.985105                108.057454   \n",
       "1971-01-25 11:06:52                     5280.039368                108.057448   \n",
       "1971-01-25 11:06:53                     5280.058748                108.057442   \n",
       "\n",
       "                          mode  \n",
       "timepoints                      \n",
       "1971-01-25 11:06:49  operation  \n",
       "1971-01-25 11:06:50  operation  \n",
       "1971-01-25 11:06:51  operation  \n",
       "1971-01-25 11:06:52  operation  \n",
       "1971-01-25 11:06:53  operation  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Download the dataset for predict\n",
    "PATH_TO_PREDICT = r'C:\\Users\\yzh086\\OneDrive - University of Bergen\\hackthon_code\\data\\prediction_input.parquet'\n",
    "data_predict = pd.read_parquet(PATH_TO_PREDICT)\n",
    "data_predict.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "6f7227a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.replace({'operation':1,'start':0})\n",
    "data_predict = data_predict.replace({'operation':1,'start':0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a406f733",
   "metadata": {},
   "outputs": [],
   "source": [
    "# split train and label data\n",
    "data_train = data.drop(columns=['Bolt_1_Tensile','Bolt_2_Tensile','Bolt_3_Tensile','Bolt_4_Tensile'\n",
    "                        ,'Bolt_5_Tensile','Bolt_6_Tensile'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79260661",
   "metadata": {},
   "outputs": [],
   "source": [
    "data_label = data.loc[:,['Bolt_1_Tensile','Bolt_2_Tensile','Bolt_3_Tensile','Bolt_4_Tensile'\n",
    "                        ,'Bolt_5_Tensile','Bolt_6_Tensile']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "6f2e4e65",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reduce the memory for a large dataset used\n",
    "def reduce_mem_usage(df, verbose=True):\n",
    "    numerics = ['int16', 'int32', 'int64', 'float16', 'float32', 'float64']\n",
    "    #objecttype=['object']\n",
    "    start_mem = df.memory_usage().sum() / 1024**2    \n",
    "    for col in df.columns:\n",
    "        col_type = df[col].dtypes\n",
    "        if col_type in numerics:\n",
    "            c_min = df[col].min()\n",
    "            c_max = df[col].max()\n",
    "            if str(col_type)[:3] == 'int':\n",
    "                if c_min > np.iinfo(np.int8).min and c_max < np.iinfo(np.int8).max:\n",
    "                    df[col] = df[col].astype(np.int8)\n",
    "                elif c_min > np.iinfo(np.int16).min and c_max < np.iinfo(np.int16).max:\n",
    "                    df[col] = df[col].astype(np.int16)\n",
    "                elif c_min > np.iinfo(np.int32).min and c_max < np.iinfo(np.int32).max:\n",
    "                    df[col] = df[col].astype(np.int32)\n",
    "                elif c_min > np.iinfo(np.int64).min and c_max < np.iinfo(np.int64).max:\n",
    "                    df[col] = df[col].astype(np.int64)  \n",
    "            else:\n",
    "                if c_min > np.finfo(np.float16).min and c_max < np.finfo(np.float16).max:\n",
    "                    df[col] = df[col].astype(np.float16)\n",
    "                elif c_min > np.finfo(np.float32).min and c_max < np.finfo(np.float32).max:\n",
    "                    df[col] = df[col].astype(np.float32)\n",
    "                else:\n",
    "                    df[col] = df[col].astype(np.float64)\n",
    "        #if col_type in objecttype:\n",
    "            #df[col]=df[col].astype('category')\n",
    "    end_mem = df.memory_usage().sum() / 1024**2\n",
    "    if verbose: print('Mem. usage decreased to {:5.2f} Mb ({:.1f}% reduction)'.format(end_mem, 100 * (start_mem - end_mem) / start_mem))\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2f288585",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Defining function to fit and evaluate models\n",
    "\n",
    "from sklearn.ensemble import GradientBoostingClassifier #For Classification\n",
    "from sklearn.ensemble import GradientBoostingRegressor #For Regression\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "\n",
    "def regr(Model, X_train, Y_train, X_test, Y_test):\n",
    "    # Random forest \n",
    "    if Model=='rf':\n",
    "    # define the model\n",
    "\n",
    "        model = RandomForestRegressor()\n",
    "        model.fit(X_train, Y_train.values.ravel()) \n",
    "        Y_fit = model.predict(X_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        plt.scatter(Y_fit,Y_train)\n",
    "        plt.scatter(Y_pred,Y_test)\n",
    "        \n",
    "        return model, Y_pred\n",
    "        \n",
    "    if Model == 'GDB':\n",
    "        model = GradientBoostingRegressor(random_state=0)\n",
    "        model.fit(X_train, Y_train)\n",
    "        Y_fit = model.predict(X_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        print('GradientBoostingRegressor accuracy: {}'.format(model.score(X_train,Y_train)))\n",
    "        #print(f'The accuracy score: {accuracy_score(Y_test, Y_pred)}')\n",
    "        #print(f'The F1 Score is: {f1_score(Y_test, Y_pred)}')\n",
    "        plt.scatter(Y_fit,Y_train)\n",
    "        plt.scatter(Y_pred,Y_test)\n",
    "        return model, Y_pred\n",
    "\n",
    "    # Linear regression\n",
    "    if Model == 'mlr':\n",
    "        # define the model\n",
    "        model = LinearRegression().fit(X_train, Y_train)\n",
    "        print(model.score(X_train,Y_train))\n",
    "        Y_fit = model.predict(X_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        plt.scatter(Y_fit,Y_train)\n",
    "        plt.scatter(Y_pred,Y_test)\n",
    "        return model, Y_pred\n",
    "\n",
    "    # Neural Network\n",
    "    if Model == 'ANN':\n",
    "        model = Sequential()\n",
    "        model.add(Dense(32, input_dim=1, kernel_initializer='normal', activation='relu'))\n",
    "        model.add(Dense(16, kernel_initializer='normal'))\n",
    "        model.add(Dense(1, kernel_initializer='normal'))\n",
    "        model.compile(loss='mean_squared_error', optimizer='adam')\n",
    "\n",
    "        # fit the keras model on the dataset\n",
    "        model.fit(X_train, Y_train, epochs=150, batch_size=10)\n",
    "        Y_fit = model.predict(X_train)\n",
    "        Y_pred = model.predict(X_test)\n",
    "        return model, Y_pred\n",
    "\n",
    "    # Rating Curve\n",
    "    if Model == 'rc':\n",
    "        params, _ = curve_fit(rc,X_train['Water Level'],Y_train)\n",
    "        par1, par2, par3 = params\n",
    "\n",
    "        Y_fit = rc(X_train['Water Level'],par1,par2,par3)\n",
    "        Y_pred = rc(X_test['Water Level'],par1, par2, par3)\n",
    "\n",
    "        print(params)\n",
    "\n",
    "    print('MAPE train ' + str(mean_squared_error(Y_train, Y_fit)))\n",
    "    print('MAPE test ' + str(mean_squared_error(Y_test, Y_pred)))\n",
    "    print('MAPE train ' + str(mean_absolute_percentage_error(Y_train, Y_fit)))\n",
    "    print('MAPE test ' + str(mean_absolute_percentage_error(Y_test, Y_pred)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6365df86",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model for bolt4 ##\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "cols = data_predict.columns\n",
    "cols = cols.to_list()\n",
    "mys = 'Bolt_4_Tensile'\n",
    "cols.append(mys)\n",
    "\n",
    "#data = data.replace({'operation':1,'start':0})\n",
    "\n",
    "df = data[cols]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "seed = 666                    # Fix random seed for reproducibility\n",
    "# Shuffle and split the data into train and a concatenation of validation and test sets with a ratio of 0.7/0.3:\n",
    "X = df.loc[:, df.columns != 'Bolt_4_Tensile']\n",
    "Y = df.loc[:, df.columns == 'Bolt_4_Tensile']\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y,      \n",
    "                                                                            test_size=.05, \n",
    "                                                                            shuffle=True, \n",
    "                                                                            random_state=seed)\n",
    "# Store number of datapoints in each dataset:\n",
    "N_train = len(Y_train)\n",
    "N_test = len(Y_test)\n",
    "print(\"Datapoints used for training:   \", N_train)\n",
    "print(\"Datapoints used for testing :   \", N_test)\n",
    "\n",
    "X_train = reduce_mem_usage(X_train, verbose=True)\n",
    "\n",
    "X_test = reduce_mem_usage(X_test, verbose=True)\n",
    "\n",
    "Y_train = reduce_mem_usage(Y_train, verbose=True)\n",
    "\n",
    "Y_test = reduce_mem_usage(Y_test, verbose=True)\n",
    "\n",
    "X = reduce_mem_usage(X, verbose=True)\n",
    "\n",
    "Y = reduce_mem_usage(Y, verbose=True)\n",
    "\n",
    "l_bolt4, pred_bolt4 = regr('rf', X_train[:300000], Y_train[:300000], X_test[:15000], Y_test[:15000])\n",
    "\n",
    "import pickle\n",
    "filename = 'l_bolt4.plk'\n",
    "pickle.dump(l_bolt4, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0d6c10e5",
   "metadata": {},
   "outputs": [],
   "source": [
    "## model for bolt5 ##\n",
    "from sklearn import tree\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.metrics import mean_absolute_percentage_error\n",
    "from sklearn import model_selection\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import RepeatedStratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import RepeatedKFold\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "cols = data_predict.columns\n",
    "cols = cols.to_list()\n",
    "mys = 'Bolt_4_Tensile'\n",
    "cols.append(mys)\n",
    "\n",
    "#data = data.replace({'operation':1,'start':0})\n",
    "\n",
    "df = data[cols]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "seed = 666                    # Fix random seed for reproducibility\n",
    "# Shuffle and split the data into train and a concatenation of validation and test sets with a ratio of 0.7/0.3:\n",
    "X = df.loc[:, df.columns != 'Bolt_4_Tensile']\n",
    "Y = df.loc[:, df.columns == 'Bolt_4_Tensile']\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y,      \n",
    "                                                                            test_size=.05, \n",
    "                                                                            shuffle=True, \n",
    "                                                                            random_state=seed)\n",
    "# Store number of datapoints in each dataset:\n",
    "N_train = len(Y_train)\n",
    "N_test = len(Y_test)\n",
    "print(\"Datapoints used for training:   \", N_train)\n",
    "print(\"Datapoints used for testing :   \", N_test)\n",
    "\n",
    "X_train = reduce_mem_usage(X_train, verbose=True)\n",
    "\n",
    "X_test = reduce_mem_usage(X_test, verbose=True)\n",
    "\n",
    "Y_train = reduce_mem_usage(Y_train, verbose=True)\n",
    "\n",
    "Y_test = reduce_mem_usage(Y_test, verbose=True)\n",
    "\n",
    "X = reduce_mem_usage(X, verbose=True)\n",
    "\n",
    "Y = reduce_mem_usage(Y, verbose=True)\n",
    "\n",
    "l_bolt5, pred_bolt5 = regr('rf', X_train[:300000], Y_train[:300000], X_test[:15000], Y_test[:15000])\n",
    "\n",
    "import pickle\n",
    "filename = 'l_bolt5.plk'\n",
    "pickle.dump(l_bolt5, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0da36763",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2nd step model: from bolt 4 and 5 to bolt 1,2,3,6 tensile\n",
    "### 4,5 to bolt 1/2/3/6 ### for Bolt 1\n",
    "cols = ['Bolt_4_Tensile', 'Bolt_5_Tensile']\n",
    "\n",
    "mys = 'Bolt_1_Tensile'\n",
    "cols.append(mys)\n",
    "\n",
    "#data = data.replace({'operation':1,'start':0})\n",
    "\n",
    "df = data[cols]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "seed = 666                    # Fix random seed for reproducibility\n",
    "# Shuffle and split the data into train and a concatenation of validation and test sets with a ratio of 0.7/0.3:\n",
    "X = df.loc[:, df.columns != 'Bolt_1_Tensile']\n",
    "Y = df.loc[:, df.columns == 'Bolt_1_Tensile']\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y,      \n",
    "                                                                            test_size=.05, \n",
    "                                                                            shuffle=True, \n",
    "                                                                            random_state=seed)\n",
    "# Store number of datapoints in each dataset:\n",
    "N_train = len(Y_train)\n",
    "N_test = len(Y_test)\n",
    "print(\"Datapoints used for training:   \", N_train)\n",
    "print(\"Datapoints used for testing :   \", N_test)\n",
    "\n",
    "\n",
    "X_train = reduce_mem_usage(X_train, verbose=True)\n",
    "\n",
    "X_test = reduce_mem_usage(X_test, verbose=True)\n",
    "\n",
    "Y_train = reduce_mem_usage(Y_train, verbose=True)\n",
    "\n",
    "Y_test = reduce_mem_usage(Y_test, verbose=True)\n",
    "\n",
    "X = reduce_mem_usage(X, verbose=True)\n",
    "\n",
    "Y = reduce_mem_usage(Y, verbose=True)\n",
    "\n",
    "l_bolt1, pred_bolt1 = regr('rf', X_train[:300000], Y_train[:300000], X_test[:15000], Y_test[:15000])\n",
    "\n",
    "import pickle\n",
    "filename = 'l_bolt1.plk'\n",
    "pickle.dump(l_bolt1, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cbffa5c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2nd step model: from bolt 4 and 5 to bolt 1,2,3,6 tensile\n",
    "### 4,5 to bolt 1/2/3/6 ### for Bolt2\n",
    "cols = ['Bolt_4_Tensile', 'Bolt_5_Tensile']\n",
    "\n",
    "mys = 'Bolt_2_Tensile'\n",
    "cols.append(mys)\n",
    "\n",
    "#data = data.replace({'operation':1,'start':0})\n",
    "\n",
    "df = data[cols]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "seed = 666                    # Fix random seed for reproducibility\n",
    "# Shuffle and split the data into train and a concatenation of validation and test sets with a ratio of 0.7/0.3:\n",
    "X = df.loc[:, df.columns != 'Bolt_2_Tensile']\n",
    "Y = df.loc[:, df.columns == 'Bolt_2_Tensile']\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y,      \n",
    "                                                                            test_size=.05, \n",
    "                                                                            shuffle=True, \n",
    "                                                                            random_state=seed)\n",
    "# Store number of datapoints in each dataset:\n",
    "N_train = len(Y_train)\n",
    "N_test = len(Y_test)\n",
    "print(\"Datapoints used for training:   \", N_train)\n",
    "print(\"Datapoints used for testing :   \", N_test)\n",
    "\n",
    "X_train = reduce_mem_usage(X_train, verbose=True)\n",
    "\n",
    "X_test = reduce_mem_usage(X_test, verbose=True)\n",
    "\n",
    "Y_train = reduce_mem_usage(Y_train, verbose=True)\n",
    "\n",
    "Y_test = reduce_mem_usage(Y_test, verbose=True)\n",
    "\n",
    "X = reduce_mem_usage(X, verbose=True)\n",
    "\n",
    "Y = reduce_mem_usage(Y, verbose=True)\n",
    "\n",
    "l_bolt2, pred_bolt2 = regr('rf', X_train[:300000], Y_train[:300000], X_test[:15000], Y_test[:15000])\n",
    "\n",
    "import pickle\n",
    "filename = 'l_bolt2.plk'\n",
    "pickle.dump(l_bolt2, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e7cf3b72",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2nd step model: from bolt 4 and 5 to bolt 1,2,3,6 tensile\n",
    "### 4,5 to bolt 1/2/3/6 ### for Bolt 3\n",
    "cols = ['Bolt_4_Tensile', 'Bolt_5_Tensile']\n",
    "\n",
    "mys = 'Bolt_3_Tensile'\n",
    "cols.append(mys)\n",
    "\n",
    "#data = data.replace({'operation':1,'start':0})\n",
    "\n",
    "df = data[cols]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "seed = 666                    # Fix random seed for reproducibility\n",
    "# Shuffle and split the data into train and a concatenation of validation and test sets with a ratio of 0.7/0.3:\n",
    "X = df.loc[:, df.columns != 'Bolt_3_Tensile']\n",
    "Y = df.loc[:, df.columns == 'Bolt_3_Tensile']\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y,      \n",
    "                                                                            test_size=.05, \n",
    "                                                                            shuffle=True, \n",
    "                                                                            random_state=seed)\n",
    "# Store number of datapoints in each dataset:\n",
    "N_train = len(Y_train)\n",
    "N_test = len(Y_test)\n",
    "print(\"Datapoints used for training:   \", N_train)\n",
    "print(\"Datapoints used for testing :   \", N_test)\n",
    "\n",
    "X_train = reduce_mem_usage(X_train, verbose=True)\n",
    "\n",
    "X_test = reduce_mem_usage(X_test, verbose=True)\n",
    "\n",
    "Y_train = reduce_mem_usage(Y_train, verbose=True)\n",
    "\n",
    "Y_test = reduce_mem_usage(Y_test, verbose=True)\n",
    "\n",
    "X = reduce_mem_usage(X, verbose=True)\n",
    "\n",
    "Y = reduce_mem_usage(Y, verbose=True)\n",
    "\n",
    "\n",
    "l_bolt3, pred_bolt3 = regr('rf', X_train[:300000], Y_train[:300000], X_test[:15000], Y_test[:15000])\n",
    "\n",
    "import pickle\n",
    "filename = 'l_bolt3.plk'\n",
    "pickle.dump(l_bolt3, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b4de797c",
   "metadata": {},
   "outputs": [],
   "source": [
    "### 2nd step model: from bolt 4 and 5 to bolt 1,2,3,6 tensile\n",
    "### 4,5 to bolt 1/2/3/6 ### for Bolt 6\n",
    "cols = ['Bolt_4_Tensile', 'Bolt_5_Tensile']\n",
    "\n",
    "mys = 'Bolt_6_Tensile'\n",
    "cols.append(mys)\n",
    "\n",
    "#data = data.replace({'operation':1,'start':0})\n",
    "\n",
    "df = data[cols]\n",
    "df.dropna(inplace=True)\n",
    "\n",
    "seed = 666                    # Fix random seed for reproducibility\n",
    "# Shuffle and split the data into train and a concatenation of validation and test sets with a ratio of 0.7/0.3:\n",
    "X = df.loc[:, df.columns != 'Bolt_6_Tensile']\n",
    "Y = df.loc[:, df.columns == 'Bolt_6_Tensile']\n",
    "X_train, X_test, Y_train, Y_test = model_selection.train_test_split(X, Y,      \n",
    "                                                                            test_size=.05, \n",
    "                                                                            shuffle=True, \n",
    "                                                                            random_state=seed)\n",
    "# Store number of datapoints in each dataset:\n",
    "N_train = len(Y_train)\n",
    "N_test = len(Y_test)\n",
    "print(\"Datapoints used for training:   \", N_train)\n",
    "print(\"Datapoints used for testing :   \", N_test)\n",
    "\n",
    "X_train = reduce_mem_usage(X_train, verbose=True)\n",
    "\n",
    "X_test = reduce_mem_usage(X_test, verbose=True)\n",
    "\n",
    "Y_train = reduce_mem_usage(Y_train, verbose=True)\n",
    "\n",
    "Y_test = reduce_mem_usage(Y_test, verbose=True)\n",
    "\n",
    "X = reduce_mem_usage(X, verbose=True)\n",
    "\n",
    "Y = reduce_mem_usage(Y, verbose=True)\n",
    "\n",
    "\n",
    "l_bolt6, pred_bolt6 = regr('rf', X_train[:300000], Y_train[:300000], X_test[:15000], Y_test[:15000])\n",
    "\n",
    "import pickle\n",
    "filename = 'l_bolt6.plk'\n",
    "pickle.dump(l_bolt6, open(filename, 'wb'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0d859a92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# prediction of Bolt4 and Bolt5\n",
    "# read model and feed predict_data\n",
    "filename = 'l_bolt4.plk'\n",
    "l_bolt4 = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "filename = 'l_bolt5.plk'\n",
    "l_bolt5 = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "Y_pred4 = l_bolt4.predict(data_predict)\n",
    "\n",
    "\n",
    "Y_pred5 = l_bolt5.predict(data_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1564085c",
   "metadata": {},
   "outputs": [],
   "source": [
    "bolt_4_5 = np.concatenate((Y_pred4.reshape(Y_pred4.shape[0],1),Y_pred5.reshape(Y_pred5.shape[0],1)),axis = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "161b180f",
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[1606.05, 1606.08],\n",
       "       [1606.12, 1606.11],\n",
       "       [1606.21, 1606.22],\n",
       "       ...,\n",
       "       [1598.8 , 1599.09],\n",
       "       [1598.95, 1599.27],\n",
       "       [1597.54, 1598.34]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bolt_4_5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "ddddc77b",
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'l_bolt1.plk'\n",
    "l_bolt1 = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "filename = 'l_bolt2.plk'\n",
    "l_bolt2 = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "filename = 'l_bolt3.plk'\n",
    "l_bolt3 = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "filename = 'l_bolt6.plk'\n",
    "l_bolt6 = pickle.load(open(filename, 'rb'))\n",
    "\n",
    "Y_pred1 = l_bolt1.predict(bolt_4_5)\n",
    "\n",
    "\n",
    "Y_pred2 = l_bolt2.predict(bolt_4_5)\n",
    "Y_pred3 = l_bolt3.predict(bolt_4_5)\n",
    "\n",
    "Y_pred6 = l_bolt6.predict(bolt_4_5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "486bc510",
   "metadata": {},
   "outputs": [],
   "source": [
    "output = pd.DataFrame({'Bolt_1_Tensile':Y_pred1, 'Bolt_2_Tensile':Y_pred2,'Bolt_3_Tensile': Y_pred3,\n",
    "                       'Bolt_4_Tensile':Y_pred4,\n",
    "                       'Bolt_5_Tensile': Y_pred5, 'Bolt_6_Tensile': Y_pred6}, \n",
    "                      index = data_predict.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "46e97814",
   "metadata": {},
   "outputs": [],
   "source": [
    "output.to_csv('output.csv')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
